{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce309d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Create the gold fact table (run once or if schema changes needed)\n",
    "CREATE TABLE IF NOT EXISTS gold.ipl_team_vs_team_season (\n",
    "  season INT,\n",
    "  team_sk BIGINT,\n",
    "  opponent_team_sk BIGINT,\n",
    "\n",
    "  matches_played INT,\n",
    "  wins INT,\n",
    "  losses INT,\n",
    "\n",
    "  avg_runs_scored DOUBLE,\n",
    "  avg_runs_conceded DOUBLE,\n",
    "\n",
    "  ingestion_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "TBLPROPERTIES (\n",
    "  delta.autoOptimize.optimizeWrite = true,\n",
    "  delta.autoOptimize.autoCompact = true\n",
    ");\n",
    "-- Optional: PARTITIONED BY (season)  -- Uncomment for better performance with many seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfeddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read silver tables\n",
    "fact_matches = spark.table(\"silver.fact_matches\")\n",
    "fact_deliveries = spark.table(\"silver.fact_deliveries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Directed match pairs (one row per team per match)\n",
    "team1_df = fact_matches.select(\n",
    "    \"season\",\n",
    "    \"match_id\",\n",
    "    F.col(\"team1_sk\").alias(\"team_sk\"),\n",
    "    F.col(\"team2_sk\").alias(\"opponent_sk\"),\n",
    "    \"winner_sk\"\n",
    ")\n",
    "team2_df = fact_matches.select(\n",
    "    \"season\",\n",
    "    \"match_id\",\n",
    "    F.col(\"team2_sk\").alias(\"team_sk\"),\n",
    "    F.col(\"team1_sk\").alias(\"opponent_sk\"),\n",
    "    \"winner_sk\"\n",
    ")\n",
    "match_teams = team1_df.union(team2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Head-to-head outcomes\n",
    "outcomes = match_teams.groupBy(\"season\", \"team_sk\", \"opponent_sk\").agg(\n",
    "    F.count(\"*\").cast(\"int\").alias(\"matches_played\"),\n",
    "    F.sum(F.when(F.col(\"winner_sk\") == F.col(\"team_sk\"), 1).otherwise(0)).cast(\"int\").alias(\"wins\"),\n",
    "    F.sum(F.when(F.col(\"winner_sk\") == F.col(\"opponent_sk\"), 1).otherwise(0)).cast(\"int\").alias(\"losses\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Runs scored (team batting against opponent) - exclude super overs\n",
    "runs_scored_df = fact_deliveries \\\n",
    "    .join(fact_matches.select(\"match_id\", \"season\"), \"match_id\") \\\n",
    "    .filter(F.col(\"is_super_over\") == 0) \\\n",
    "    .groupBy(\"season\", F.col(\"batting_team_sk\").alias(\"team_sk\"), F.col(\"bowling_team_sk\").alias(\"opponent_sk\")) \\\n",
    "    .agg(F.sum(\"total_runs\").alias(\"runs_scored_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7afdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Runs conceded (team bowling against opponent) - exclude super overs\n",
    "runs_conceded_df = fact_deliveries \\\n",
    "    .join(fact_matches.select(\"match_id\", \"season\"), \"match_id\") \\\n",
    "    .filter(F.col(\"is_super_over\") == 0) \\\n",
    "    .groupBy(\"season\", F.col(\"bowling_team_sk\").alias(\"team_sk\"), F.col(\"batting_team_sk\").alias(\"opponent_sk\")) \\\n",
    "    .agg(F.sum(\"total_runs\").alias(\"runs_conceded_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226728ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Assemble final DataFrame\n",
    "gold_df = outcomes \\\n",
    "    .join(runs_scored_df, [\"season\", \"team_sk\", \"opponent_sk\"], \"left\") \\\n",
    "    .join(runs_conceded_df, [\"season\", \"team_sk\", \"opponent_sk\"], \"left\") \\\n",
    "    .select(\n",
    "        \"season\",\n",
    "        \"team_sk\",\n",
    "        \"opponent_sk\",\n",
    "        \"matches_played\",\n",
    "        \"wins\",\n",
    "        \"losses\",\n",
    "        F.when(\n",
    "            F.col(\"matches_played\") > 0,\n",
    "            F.round(F.coalesce(F.col(\"runs_scored_total\"), F.lit(0.0)) / F.col(\"matches_played\"), 2)\n",
    "        ).otherwise(F.lit(0.0)).alias(\"avg_runs_scored\"),\n",
    "        F.when(\n",
    "            F.col(\"matches_played\") > 0,\n",
    "            F.round(F.coalesce(F.col(\"runs_conceded_total\"), F.lit(0.0)) / F.col(\"matches_played\"), 2)\n",
    "        ).otherwise(F.lit(0.0)).alias(\"avg_runs_conceded\"),\n",
    "        F.current_timestamp().alias(\"ingestion_ts\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c788ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to gold table (full overwrite - no duplicates due to (season, team_sk, opponent_sk) grain)\n",
    "gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.ipl_team_vs_team_season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
     ]
    }
   ],
   "source": [
    "# Optimize (Z-order by common query patterns)\n",
    "spark.sql(\"OPTIMIZE gold.ipl_team_vs_team_season ZORDER BY (season, team_sk)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
