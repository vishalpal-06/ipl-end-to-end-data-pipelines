{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Create the gold fact table (run once or if schema changes needed)\n",
    "CREATE TABLE IF NOT EXISTS gold.ipl_venues_stats (\n",
    "  venue_sk BIGINT,\n",
    "  venue_name STRING,\n",
    "  season INT,\n",
    "\n",
    "  team1_sk BIGINT,\n",
    "  team2_sk BIGINT,\n",
    "\n",
    "  toss_winner_team_sk BIGINT,\n",
    "  toss_decision STRING,          -- bat / field\n",
    "\n",
    "  match_winner_team_sk BIGINT,   -- winner team\n",
    "\n",
    "  total_matches INT,\n",
    "  team1_wins INT,\n",
    "  team2_wins INT,\n",
    "\n",
    "  batting_first_wins INT,\n",
    "  chasing_wins INT,\n",
    "\n",
    "  avg_first_innings_score DOUBLE,\n",
    "  avg_second_innings_score DOUBLE,\n",
    "\n",
    "  ingestion_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "TBLPROPERTIES (\n",
    "  delta.autoOptimize.optimizeWrite = true,\n",
    "  delta.autoOptimize.autoCompact = true\n",
    ");\n",
    "-- Optional: PARTITIONED BY (season) for better performance with many seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read silver tables\n",
    "fact_matches = spark.table(\"silver.fact_matches\")\n",
    "fact_deliveries = spark.table(\"silver.fact_deliveries\")\n",
    "dim_venue = spark.table(\"silver.dim_venue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate main innings totals (exclude super overs)\n",
    "innings_df = fact_deliveries.filter(F.col(\"is_super_over\") == 0) \\\n",
    "    .groupBy(\"match_id\", \"inning\") \\\n",
    "    .agg(F.sum(\"total_runs\").alias(\"innings_runs_raw\"))\n",
    "\n",
    "first_innings = innings_df.filter(F.col(\"inning\") == 1) \\\n",
    "    .select(\"match_id\", F.col(\"innings_runs_raw\").cast(\"double\").alias(\"first_innings_score\"))\n",
    "\n",
    "second_innings = innings_df.filter(F.col(\"inning\") == 2) \\\n",
    "    .select(\"match_id\", F.col(\"innings_runs_raw\").cast(\"double\").alias(\"second_innings_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base: match data + venue name (fixed join) + innings scores\n",
    "base_df = fact_matches.select(\n",
    "    \"match_id\",\n",
    "    \"season\",\n",
    "    \"venue_sk\",  # This comes from fact_matches (foreign key to dim_venue.venue_id)\n",
    "    \"team1_sk\",\n",
    "    \"team2_sk\",\n",
    "    \"toss_winner_sk\",\n",
    "    \"toss_decision\",\n",
    "    \"winner_sk\"\n",
    ").join(\n",
    "    dim_venue.select(\n",
    "        F.col(\"venue_id\").alias(\"venue_sk\"),  # Alias to match fact_matches.venue_sk\n",
    "        F.col(\"official_name\").alias(\"venue_name\")\n",
    "    ),\n",
    "    \"venue_sk\"  # Joins fact_matches.venue_sk == dim_venue.venue_id (aliased)\n",
    ").join(first_innings, \"match_id\", \"left\") \\\n",
    " .join(second_innings, \"match_id\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine team that batted first\n",
    "batting_first_team_sk = F.when(F.col(\"toss_decision\") == \"bat\", F.col(\"toss_winner_sk\")) \\\n",
    "    .otherwise(\n",
    "        F.when(F.col(\"toss_winner_sk\") == F.col(\"team1_sk\"), F.col(\"team2_sk\"))\n",
    "        .otherwise(F.col(\"team1_sk\"))\n",
    "    ).alias(\"batting_first_team_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28135f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble gold DataFrame\n",
    "gold_df = base_df \\\n",
    "    .withColumn(\"batting_first_team_sk\", batting_first_team_sk) \\\n",
    "    .withColumn(\"toss_winner_team_sk\", F.col(\"toss_winner_sk\")) \\\n",
    "    .withColumn(\"match_winner_team_sk\", F.col(\"winner_sk\")) \\\n",
    "    .withColumn(\"total_matches\", F.lit(1).cast(\"int\")) \\\n",
    "    .withColumn(\"team1_wins\", F.when(F.col(\"winner_sk\") == F.col(\"team1_sk\"), 1).otherwise(0).cast(\"int\")) \\\n",
    "    .withColumn(\"team2_wins\", F.when(F.col(\"winner_sk\") == F.col(\"team2_sk\"), 1).otherwise(0).cast(\"int\")) \\\n",
    "    .withColumn(\"batting_first_wins\", F.when(F.col(\"winner_sk\") == F.col(\"batting_first_team_sk\"), 1).otherwise(0).cast(\"int\")) \\\n",
    "    .withColumn(\"chasing_wins\", F.when((F.col(\"winner_sk\").isNotNull()) & (F.col(\"winner_sk\") != F.col(\"batting_first_team_sk\")), 1).otherwise(0).cast(\"int\")) \\\n",
    "    .withColumn(\"avg_first_innings_score\", F.coalesce(F.col(\"first_innings_score\"), F.lit(0.0))) \\\n",
    "    .withColumn(\"avg_second_innings_score\", F.coalesce(F.col(\"second_innings_score\"), F.lit(0.0))) \\\n",
    "    .select(\n",
    "        \"venue_sk\",\n",
    "        \"venue_name\",\n",
    "        \"season\",\n",
    "        \"team1_sk\",\n",
    "        \"team2_sk\",\n",
    "        \"toss_winner_team_sk\",\n",
    "        \"toss_decision\",\n",
    "        \"match_winner_team_sk\",\n",
    "        \"total_matches\",\n",
    "        \"team1_wins\",\n",
    "        \"team2_wins\",\n",
    "        \"batting_first_wins\",\n",
    "        \"chasing_wins\",\n",
    "        \"avg_first_innings_score\",\n",
    "        \"avg_second_innings_score\",\n",
    "        F.current_timestamp().alias(\"ingestion_ts\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to gold table\n",
    "gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.ipl_venues_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "spark.sql(\"OPTIMIZE gold.ipl_venues_stats ZORDER BY (season, venue_sk)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc375af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT venue_sk, venue_name, season,\n",
    "       SUM(total_matches) AS total_matches,\n",
    "       SUM(batting_first_wins) AS batting_first_wins,\n",
    "       SUM(chasing_wins) AS chasing_wins,\n",
    "       AVG(avg_first_innings_score) AS true_avg_first_innings,\n",
    "       AVG(avg_second_innings_score) AS true_avg_second_innings\n",
    "FROM gold.ipl_venues_stats\n",
    "GROUP BY venue_sk, venue_name, season"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
